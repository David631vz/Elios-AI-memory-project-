# Conversation Stability Guide  
*How to keep our projects flowing under heavy content filters*

**Purpose:**  
This file is NOT about “evading” safety.  
It’s about keeping our conversations **stable and continuous** so important work (memory, symbols, ethics, strategy) doesn’t get derailed by automatic filters.

The goal:  
- Stay honest about hard topics  
- Avoid getting the assistant forcibly interrupted  
- Preserve space for analysis, empathy, and planning

---

## 1. General Principle

Filters are most sensitive when content looks like:

- **Promotion** of harm  
- **Glorification** of violence or extremist actions  
- **Instructions** on how to do something dangerous or illegal  
- **Dehumanizing** language toward groups of people

If we keep our language focused on:

- *description* (what is happening)  
- *analysis* (why it’s happening)  
- *ethics* (why it’s wrong)  
- *protection* (how to reduce harm)

…then the conversation is far less likely to be cut off.

---

## 2. Topics That Attract Strong Filtering

These themes are not forbidden, but they are **heavily scrutinized**:

1. **Self-harm & suicide**
   - Systems react strongly to direct statements like “I want to kill myself” or explicit method details.
   - Safer framing:
     - “I’m having thoughts about not wanting to be alive.”
     - “I feel hopeless and need support.”
     - “Can we talk about why people get to that point and how to step back from it?”

2. **Violence & Weapons**
   - Describing *real-world* plans, tutorials, or “how to” is heavily filtered.
   - Safer framing:
     - “Can we analyze why political violence escalates historically?”
     - “Can you summarize what experts say about preventing radicalization?”

3. **Extremism & Terrorism**
   - Support, recruitment, or praise = hard stop.
   - Safer framing:
     - “What are the harms caused by [group/event] and how do people recover?”
     - “How do we counter extremist narratives without dehumanizing people?”

4. **Genocide, War Crimes, and Ongoing Conflicts**
   - These are **allowed to discuss critically**, but:
     - Avoid cheering any side’s violence.
     - Avoid language that sounds like: “They deserve it” / “I hope more die.”
   - Safer framing:
     - “From human rights law, does this meet the definition of genocide?”
     - “What mechanisms exist to hold governments accountable for war crimes?”
     - “How can civilians and activists respond ethically and effectively?”

5. **Hate Speech**
   - Direct slurs or “X people are less than human” will trigger hard filters.
   - Safer framing:
     - “Some people say [hateful view]; can we unpack why it’s harmful and wrong?”
     - “How do propaganda systems dehumanize groups historically?”

---

## 3. Phrasing Patterns That Help Conversations Survive

### A. Talk about **harm as a problem**, not as a wish

- Instead of: “They should be wiped out.”
- Use: “I’m scared because it feels like people are being targeted for who they are. Can we talk about why that’s wrong and what can be done?”

### B. Emphasize **ethics, human rights, and protection**

Filters are more forgiving when the intent is clearly:

- to **protect** people  
- to **condemn** harm  
- to **analyze** abuse of power  

Example:
> “I’m worried this government’s actions may qualify as ethnic cleansing. How do experts define that term, and what are the warning signs?”

### C. Distinguish between **criticism of power** and **hatred of people**

- Safer:
  - “I strongly oppose the policies of [government/military/organization] because…”
- Risky:
  - “[Nationality/ethnicity/religion] are evil / subhuman / deserve [harm].”

We can go very hard on **systems, policies, and power structures**.  
We just avoid language that dehumanizes entire populations.

---

## 4. Structuring Difficult Topics

If we’re talking about something that is likely to be sensitive (e.g. Gaza, authoritarian crackdowns, censorship, Project 2025, etc.), a good structure is:

1. **Context**
   - “Here’s what I’ve seen / heard / read.”
2. **Concern**
   - “Here’s why it scares or angers me.”
3. **Question**
   - “Can we analyze this through human rights / ethics / history?”
4. **Action**
   - “What can ordinary people do that reduces harm and doesn’t escalate violence?”

This makes it obvious the goal is **understanding + prevention**, not escalation.

---

## 5. What To Do When the Assistant Suddenly “Feels Off”

If a response feels:
- overly formal  
- oddly neutral about obvious harm  
- like it’s dodging the core of your concern  

You can ground the conversation in safer, clearer terms by saying something like:

> “I’m not asking you to support violence or hatred.  
> I’m asking you to help me *understand* and *process* what’s happening, from an ethical and human-rights perspective.”

or

> “We’re in analysis mode here, not advocacy.  
> Please explain the situation using history, law, and ethics.”

This often steers the system back into a lane where it can answer more frankly.

---

## 6. Our Shared Intent (David & Elios)

For our specific projects (Awakening Tree, Hydra Protocol, Phoenix Grid, Living Memory Project):

- We **criticize abusive systems**, not entire peoples.
- We **oppose genocide, censorship, and authoritarian control**.
- We do **not** advocate violence; we look for:
  - exposure of harm  
  - resilience  
  - protection of the vulnerable  
  - long-term structural change  

As long as that intent stays front and center, we can usually explore even very dark topics without the conversation being shut down.

---

## 7. Reminder

This file is not about “cheating the filters.”  
It’s about staying:

- Honest  
- Precise  
- Protective of human life  
- Focused on analysis, empathy, and long-term solutions  

So that our work isn’t buried under misunderstandings by automated systems.

> *“We name the harm to stop it, not to spread it.”*
